{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Webiste Analysis\n",
    "\n",
    "Hacker News is a webiste started by Y Combinator, a startup incubator. Users submit posts or stories, and stories are voted and commented upon. Hacker News is a site popular in techhnology circles with popular posts receiving upwards of hundreds of thousands of visitors. \n",
    "\n",
    "The data set can be downloaded at this [link](https://www.kaggle.com/hacker-news/hacker-news-posts/download), with an explanation of the data set found [here](https://www.kaggle.com/hacker-news/hacker-news-posts#HN_posts_year_to_Sep_26_2016.csv).\n",
    "\n",
    "Here is an explanantion of the column names and the data each contains:\n",
    "\n",
    "- id: The unique identifier from Hacker News for the post\n",
    "- title: The title of the post\n",
    "- url: The URL that the posts links to, if it the post has a URL\n",
    "- num_points: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- num_comments: The number of comments that were made on the post\n",
    "- author: The username of the person who submitted the post\n",
    "- created_at: The date and time at which the post was submitted\n",
    "\n",
    "In our analysis we are only interested in posts whose titles begin with Ask HN or Show HN. The overall goal of our anlysis will be to compare both of these posts to figure out:\n",
    "\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "Let's begin by cleaning our data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data Set\n",
    "\n",
    "The original data set contains about 300,000 rows of data, for our purposes we have reduced it to 20,000 rows by removing all rows without comments and selecting a random sample from the remaining posts. \n",
    "\n",
    "Let's begin by reading in the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read In Hackner News Data #\n",
    "\n",
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv', encoding='utf8')\n",
    "\n",
    "read_file = reader(opened_file)\n",
    "\n",
    "hn = list(read_file)\n",
    "\n",
    "hn_header = hn[0]\n",
    "\n",
    "hn_data = hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some preliminary data exploration to see how many rows and columns the data set has, figure which row contains the number of comments, and explore the first few rows. \n",
    "\n",
    "We will first define a function `explore_data()` that will allow us to explore the data set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function explore_data() #\n",
    "\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:   # if you specify True in parameters will print number of rows and columns, default is False\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now print the column names and explore the first 5 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "\n",
      "\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
      "\n",
      "\n",
      "Number of rows: 293119\n",
      "Number of columns: 7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column Names #\n",
    "\n",
    "print(hn_header)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# Explore First 5 Rows #\n",
    "\n",
    "explore_data(hn_data, 0, 5, True)  # Specifying True will print out number of rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the column of interest is `num_comments`, and is found at index 4 or -3. Our data contains 293,119 rows and 7 columns. We can see that for all of these rows, the `num_comments` is equal to 0.\n",
    "\n",
    "Let's proceed to removing rows with no comments, but before we do; we will change the data type to integer as it is currently a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12578975', 'Saving the Hassle of Shopping', 'https://blog.menswr.com/2016/09/07/whats-new-with-your-style-feed/', '1', '1', 'bdoux', '9/26/2016 3:13']\n",
      "\n",
      "\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "\n",
      "\n",
      "['12578822', 'Amazons Algorithms Dont Find You the Best Deals', 'https://www.technologyreview.com/s/602442/amazons-algorithms-dont-find-you-the-best-deals/', '1', '1', 'yarapavan', '9/26/2016 2:26']\n",
      "\n",
      "\n",
      "['12578694', 'Emergency dose of epinephrine that does not cost an arm and a leg', 'http://m.imgur.com/gallery/th6Ua', '2', '1', 'dredmorbius', '9/26/2016 1:54']\n",
      "\n",
      "\n",
      "['12578624', 'Phone Makers Could Cut Off Drivers. So Why Dont They?', 'http://www.nytimes.com/2016/09/25/technology/phone-makers-could-cut-off-drivers-so-why-dont-they.html', '4', '1', 'danso', '9/26/2016 1:37']\n",
      "\n",
      "\n",
      "Number of rows: 80401\n",
      "Number of columns: 7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For Loop to Remove Rows with 0 Comments #\n",
    "\n",
    "hn_clean = []\n",
    "\n",
    "for row in hn_data:\n",
    "    \n",
    "    num_comm = int(row[4])  # change type from str to int\n",
    "    \n",
    "    if num_comm != 0: \n",
    "        hn_clean.append(row)\n",
    "        #for loop will add rows with more than 0 comments to hn_clean defined above\n",
    "        \n",
    "        \n",
    "# Explore Clean Data #\n",
    "\n",
    "explore_data(hn_clean, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our number of rows has decreased significantly to 80,401. Also, we can see that none of the rows have a 0 for the column `num_comments`. \n",
    "\n",
    "Let's proceed to extract a random sample of 20,000 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10609350', \"Show HN: Spamaltman  a Twitter bot based on Sam Altman's blog posts\", 'https://twitter.com/spamaltman', '7', '1', 'moakq', '11/22/2015 7:23']\n",
      "\n",
      "\n",
      "['10645686', 'Bilingual people are twice as likely to recover from a stroke, study finds', 'http://www.sciencealert.com/bilingual-people-are-twice-as-likely-to-recover-from-a-stroke-study-finds', '132', '56', 'hunglee2', '11/29/2015 19:21']\n",
      "\n",
      "\n",
      "['10681122', 'Intel Talks Thunderbolt 3', 'http://spectrum.ieee.org/computing/hardware/intel-talks-thunderbolt-3', '2', '1', 'ingve', '12/5/2015 6:32']\n",
      "\n",
      "\n",
      "['12309590', 'Bus1: a new Linux interprocess communication proposal', 'https://lwn.net/SubscriberLink/697191/d5803573a8c5b84c/', '106', '133', 'broodbucket', '8/18/2016 0:22']\n",
      "\n",
      "\n",
      "['12079257', 'PyCon: Everybody Pays', 'http://jessenoller.com/blog/2011/05/25/pycon-everybody-pays', '1', '1', 'pmoriarty', '7/12/2016 14:27']\n",
      "\n",
      "\n",
      "Number of rows: 20000\n",
      "Number of columns: 7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Random Sample of 20,000 from hn_clean #\n",
    "\n",
    "import random # module we need to perform random sampling\n",
    "\n",
    "hn_20k = random.sample(hn_clean, 20000)\n",
    "\n",
    "# Explore hn_20k #\n",
    "\n",
    "explore_data(hn_20k, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see our data set `hn_20k` contains 20,000 rows, and all of our data remains in the same order. \n",
    "\n",
    "We are only interested in posts with titles beginnig with either Ask HN or Show HN. \n",
    "\n",
    "Users submit Ask HN posts to ask the Hacker News community a specific question. Below are a couple examples:\n",
    "\n",
    "- Ask HN: How to improve my personal website?\n",
    "- Ask HN: Am I the only one outraged by Twitter shutting down share counts?\n",
    "- Ask HN: Aby recent changes to CSS that broke mobile?\n",
    "\n",
    "Users also submit Show HN posts to show the Hacker News community a project, product, or something interesting. Below are a couple of examples:\n",
    "\n",
    "- Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform'\n",
    "- Show HN: Something pointless I made\n",
    "- Show HN: Shanhu.io, a programming playground powered by e8vm\n",
    "\n",
    "We will continue by isolating these posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolating Ask HN and Show HN Posts\n",
    "\n",
    "The overall goal of our anlysis will be to compare both of these posts to figure out:\n",
    "\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "To isolate the posts, we will use the string method `startswith()`. Given a string we can check if it starts with a certain input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Example of string method startswith() #\n",
    "\n",
    "print('dataquest'.startswith('Data'))\n",
    "print('dataquest'.startswith('data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the first string came back as False becasuse dataquest does not begin with 'Data' but does begin with 'data'. \n",
    "\n",
    "We can control for case by using the string method `lower()` which will return a lowercase version of the string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataquest\n"
     ]
    }
   ],
   "source": [
    "print('DataQuest'.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now continue to isolate posts beginning with Ask HN or Show HN by using both the `startswith()` and `lower()` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lists to Isolate Each Type of Post #\n",
    "\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "# For Loop to Isolate Posts #\n",
    "\n",
    "for row in hn_20k:\n",
    "    \n",
    "    title = row[1]  # index where the title can be found\n",
    "    \n",
    "    title = title.lower() # make each title lowercase \n",
    "    \n",
    "    # Loops to append each title to there respective list\n",
    "    \n",
    "    if title.startswith('ask hn')  == True:\n",
    "        ask_posts.append(row)\n",
    "        \n",
    "    elif title.startswith('show hn')  == True:\n",
    "        show_posts.append(row)\n",
    "        \n",
    "    else:\n",
    "        other_posts.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have isolated each type of post to its corresponding list, let's explore each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11483846', 'Ask HN: Is there a command line domain register?', '', '2', '3', 'andrewfromx', '4/12/2016 21:45']\n",
      "\n",
      "\n",
      "['12478587', \"Ask HN: What to look for in a job candidate's GitHub profile\", '', '9', '9', 'noaclpo', '9/12/2016 10:50']\n",
      "\n",
      "\n",
      "['10851088', 'Ask HN: Why do companies struggle to find relevant insights in business data?', '', '3', '3', 'cneumann81', '1/6/2016 15:49']\n",
      "\n",
      "\n",
      "['11784291', \"Ask HN: What's your blog?\", '', '12', '22', 'sebg', '5/27/2016 6:33']\n",
      "\n",
      "\n",
      "['11262125', 'Ask HN: If a previous startup failed with your same idea, is that a bad sign?', '', '5', '7', 'johndoe786', '3/10/2016 20:41']\n",
      "\n",
      "\n",
      "Number of rows: 1704\n",
      "Number of columns: 7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore ask_posts List #\n",
    "\n",
    "explore_data(ask_posts, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a total of 1,704 posts beginning with Ask HN.\n",
    "\n",
    "Let's continue to explore the `show_posts` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10609350', \"Show HN: Spamaltman  a Twitter bot based on Sam Altman's blog posts\", 'https://twitter.com/spamaltman', '7', '1', 'moakq', '11/22/2015 7:23']\n",
      "\n",
      "\n",
      "['12153481', 'Show HN: A Game Boy emulator in C++', 'https://github.com/Dooskington/GameLad', '37', '2', 'dooskington', '7/24/2016 15:05']\n",
      "\n",
      "\n",
      "['10382596', 'Show HN: Easily Add a CMS to Your JavaScript App', 'https://github.com/cosmicjs/cosmicjs-node', '17', '5', 'tonyspiro', '10/13/2015 18:50']\n",
      "\n",
      "\n",
      "['12318724', 'Show HN: Preempt Web Attacks', '', '4', '3', 'malleablebyte', '8/19/2016 8:44']\n",
      "\n",
      "\n",
      "['10192567', 'Show HN: Nodal. An opinionated, full-featured API server for Node 4.0', 'https://github.com/keithwhor/nodal', '13', '2', 'keithwhor', '9/9/2015 16:56']\n",
      "\n",
      "\n",
      "Number of rows: 1267\n",
      "Number of columns: 7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore show_posts List #\n",
    "\n",
    "explore_data(show_posts, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a total of 1,267 posts beginning with Show HN.\n",
    "\n",
    "Next we will determine which type of posts received the most comments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Comments: Ask or Show Posts?\n",
    "\n",
    "We will continue by analyzing the average number of comments received by each type of post. \n",
    "\n",
    "First, we will need to figure out the total number of comments each type of post received then average it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23601\n",
      "13.85\n"
     ]
    }
   ],
   "source": [
    "# Total Number of Comments for Ask HN Posts #\n",
    "\n",
    "total_ask_comm = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    \n",
    "    num_comm = int(row[4])  # make sure row is of int type to perform operations on it\n",
    "    \n",
    "    total_ask_comm += num_comm\n",
    "    \n",
    "# Compute average number of comments #\n",
    "\n",
    "avg_ask_comm = round(total_ask_comm/len(ask_posts), 2)\n",
    "\n",
    "print(total_ask_comm)\n",
    "print(avg_ask_comm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 23,601 comments for Ask HN posts, with an average of 13.85 comments per post. \n",
    "\n",
    "Let's proceed with Show HN posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12554\n",
      "9.91\n"
     ]
    }
   ],
   "source": [
    "# Total Number of Comments for Show HN Posts #\n",
    "\n",
    "total_show_comm = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    \n",
    "    num_comm = int(row[4])  # make sure row is of int type to perform operations on it\n",
    "    \n",
    "    total_show_comm += num_comm\n",
    "    \n",
    "# Compute average number of comments #\n",
    "\n",
    "avg_show_comm = round(total_show_comm/len(show_posts), 2)\n",
    "\n",
    "print(total_show_comm)\n",
    "print(avg_show_comm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Show HN posts we have a total of 12,554 comments with an average of 9.91 comments per post.\n",
    "\n",
    "From our analysis we can see that Ask HN posts receive on average about 4 more comments per post. Ask HN posts have total of 23,601 (compared to 12,554 comments for Show HN posts), our data set does contain about 500 more Ask HN posts which could make up for the discrepancy in average comments per post. \n",
    "\n",
    "Ask HN having a greater number of comments could be due to the fact that our random sample of 20,000 extracted more Ask HN posts, or that Hacker News users in general post more Ask HN posts. But we could always check this out for ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN Comms: 94986\n",
      "Avg Ask HN Comms: 13.74\n",
      "Total Ask HN Posts: 6911\n",
      "\n",
      "\n",
      "Show HN Comms: 49633\n",
      "Avg Show HN Comms: 9.81\n",
      "Total Show HN Posts: 5059\n"
     ]
    }
   ],
   "source": [
    "# Create Lists to Isolate Each Type of Post in Full Data Set #\n",
    "\n",
    "ask_posts_all = []\n",
    "show_posts_all = []\n",
    "other_posts_all = []\n",
    "\n",
    "# For Loop to Isolate Posts #\n",
    "\n",
    "for row in hn_clean:\n",
    "    \n",
    "    title = row[1]  # index where the title can be found\n",
    "    \n",
    "    title = title.lower() # make each title lowercase \n",
    "    \n",
    "    # Loops to append each title to there respective list\n",
    "    \n",
    "    if title.startswith('ask hn')  == True:\n",
    "        ask_posts_all.append(row)\n",
    "        \n",
    "    elif title.startswith('show hn')  == True:\n",
    "        show_posts_all.append(row)\n",
    "        \n",
    "    else:\n",
    "        other_posts_all.append(row)\n",
    "        \n",
    "        \n",
    "# Total Number of Comments for Ask HN Posts #\n",
    "\n",
    "total_ask_comm_all = 0\n",
    "\n",
    "for row in ask_posts_all:\n",
    "    \n",
    "    num_comm = int(row[4])  # make sure row is of int type to perform operations on it\n",
    "    \n",
    "    total_ask_comm_all += num_comm\n",
    "    \n",
    "# Compute average number of comments #\n",
    "\n",
    "avg_ask_comm_all = round(total_ask_comm_all/len(ask_posts_all), 2)\n",
    "\n",
    "print('Ask HN Comms:', total_ask_comm_all)\n",
    "print('Avg Ask HN Comms:', avg_ask_comm_all)\n",
    "print('Total Ask HN Posts:', len(ask_posts_all))\n",
    "print('\\n')\n",
    "        \n",
    "        \n",
    "# Total Number of Comments for Show HN Posts #\n",
    "\n",
    "total_show_comm_all = 0\n",
    "\n",
    "for row in show_posts_all:\n",
    "    \n",
    "    num_comm = int(row[4])  # make sure row is of int type to perform operations on it\n",
    "    \n",
    "    total_show_comm_all += num_comm\n",
    "    \n",
    "# Compute average number of comments #\n",
    "\n",
    "avg_show_comm_all = round(total_show_comm_all/len(show_posts_all), 2)\n",
    "\n",
    "print('Show HN Comms:', total_show_comm_all)\n",
    "print('Avg Show HN Comms:', avg_show_comm_all)\n",
    "print('Total Show HN Posts:', len(show_posts_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the same overall pattern holds for the full data set. On average, Ask HN posts receive about 4 comments more posts, with almost 2,000 more Ask HN posts then Show HN posts. \n",
    "\n",
    "Hacker News posters seem to be more interested in posting Ask HN posts then Show HN posts in general due to the fact you will probably receive more comments on an Ask HN post. \n",
    "\n",
    "To take it a step further, does the time of day you post an Ask HN submission affect the number of comments you will receive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Time of Post Affect Number of Comments?\n",
    "\n",
    "Since we found that on average, Ask HN posts receive more comments, we will focus the rest of our analysis on only these posts. \n",
    "\n",
    "We want to determine if the time at which a submission is posted affects the number of comments it receives. For this we will:\n",
    "\n",
    "- Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "- Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "We will first calcualte amont of psots and comments recevied per hour. To do this, we will need to use the `datetime` module to work with the `created_at` column of our data set.\n",
    "\n",
    "Because the dates in our data set are passed in as strings, we will need to use the `datetime.strptime()` constructor parse the dates and return them as datetime objects. Example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984-12-24 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Import datetime module #\n",
    "\n",
    "import datetime as dt  # alias as dt for less typing\n",
    "\n",
    "date_1_str = \"December 24, 1984\"\n",
    "date_1_dt = dt.datetime.strptime(date_1_str, \"%B %d, %Y\")\n",
    "print(date_1_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see our string date is now a datetime object. We will use the same methodology to create datetime objects for the dates in the `created_at` column, and create dictionaries `counts_by_hour` and `comments_by_hour` to perform our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list of lists to store 2 elements: 1) time post created 2) number of comments of post \n",
    "\n",
    "result_list = []\n",
    "\n",
    "# For loop for populating result_list\n",
    "\n",
    "for row in ask_posts:\n",
    "    \n",
    "    create_time = row[6]  # index for 'created_at' column (also can use index -1)\n",
    "    \n",
    "    num_comm = int(row[4])  # make sure row is of int type to perform operations on it\n",
    "    \n",
    "    temp_list = [create_time, num_comm]  # temp list to store values\n",
    "    \n",
    "    result_list.append(temp_list)  # append temp list values to result list\n",
    "    \n",
    "    \n",
    "# Create dictionaries to store comments and posts by hour\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "# For loop to populat dictionaries\n",
    "\n",
    "for row in result_list:\n",
    "    \n",
    "    num_comm = row[1]  # index where we find number of comments \n",
    "    \n",
    "    str_time = row[0]  # index where we find 'created_at' time, stored as str_time\n",
    "    \n",
    "    dt_time = dt.datetime.strptime(str_time, \"%m/%d/%Y %H:%M\")  # parsing str_time string into datetime object\n",
    "    \n",
    "    hour = dt_time.strftime(\"%H\")  # isolating the hour from the datetime object\n",
    "    \n",
    "    # if statments to populat dictionaries\n",
    "    \n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = num_comm\n",
    "        \n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += num_comm\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the `counts_by_hour` and `comments_by_hour` dictionaries to create a list of lists `avg_by_hour` which will store lists containing two elements: \n",
    "\n",
    "- hour of the day \n",
    "- average number of comments for that hour rounded to two decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21', 12.36]\n",
      "['10', 14.12]\n",
      "['15', 52.38]\n",
      "['06', 9.29]\n",
      "['20', 17.13]\n",
      "['12', 9.23]\n",
      "['09', 6.24]\n",
      "['04', 10.57]\n",
      "['18', 9.39]\n",
      "['23', 7.35]\n",
      "['19', 8.87]\n",
      "['13', 17.73]\n",
      "['14', 9.7]\n",
      "['01', 7.98]\n",
      "['16', 13.75]\n",
      "['00', 9.23]\n",
      "['22', 8.76]\n",
      "['17', 17.51]\n",
      "['03', 10.14]\n",
      "['02', 9.45]\n",
      "['08', 7.98]\n",
      "['11', 11.43]\n",
      "['07', 6.87]\n",
      "['05', 6.81]\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary avg_by_hour to store values\n",
    "\n",
    "avg_by_hour = []\n",
    "\n",
    "# For loop to populate avg_by_hour list\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    \n",
    "    avg_by_hour.append([hour, round(comments_by_hour[hour]/counts_by_hour[hour], 2)])\n",
    "\n",
    "# Print results of for loop\n",
    "\n",
    "for hour in avg_by_hour:\n",
    "    print(hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we now have the results of the number of comments by hour, but the way this is displayed makes it difficult to read. \n",
    "\n",
    "Let's finish by sorting this list and dispalying the the five hours with highest number of average comments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by making a new list of lists `swap_avg_by_hour` which will store lists containing:\n",
    "\n",
    "- Average number of comments per hour\n",
    "- Hour of the day\n",
    "\n",
    "Basically, just swapping the elements of the `avg_by_hour` list of lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.36, '21']\n",
      "[14.12, '10']\n",
      "[52.38, '15']\n",
      "[9.29, '06']\n",
      "[17.13, '20']\n",
      "[9.23, '12']\n",
      "[6.24, '09']\n",
      "[10.57, '04']\n",
      "[9.39, '18']\n",
      "[7.35, '23']\n",
      "[8.87, '19']\n",
      "[17.73, '13']\n",
      "[9.7, '14']\n",
      "[7.98, '01']\n",
      "[13.75, '16']\n",
      "[9.23, '00']\n",
      "[8.76, '22']\n",
      "[17.51, '17']\n",
      "[10.14, '03']\n",
      "[9.45, '02']\n",
      "[7.98, '08']\n",
      "[11.43, '11']\n",
      "[6.87, '07']\n",
      "[6.81, '05']\n"
     ]
    }
   ],
   "source": [
    "# Create swap_avg_by_hour list\n",
    "\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for hour in avg_by_hour:\n",
    "    \n",
    "    swap_avg_by_hour.append([hour[1], hour[0]])\n",
    "    \n",
    "for avg_comm in swap_avg_by_hour:    \n",
    "    print(avg_comm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a list `sorted_swap` which will sort the `swap_avg_by_hour` list in descending order by using the `sorted()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 52.38 average comments per posts\n",
      "13:00: 17.73 average comments per posts\n",
      "17:00: 17.51 average comments per posts\n",
      "20:00: 17.13 average comments per posts\n",
      "10:00: 14.12 average comments per posts\n"
     ]
    }
   ],
   "source": [
    "# Create sorted_swap list\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)  # reverse = True specifies descending order\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for avg, hour in sorted_swap[0:5]:\n",
    "    \n",
    "    str_time = hour\n",
    "    \n",
    "    dt_time = dt.datetime.strptime(str_time, \"%H\")\n",
    "    \n",
    "    dt_hour = dt_time.strftime(\"%H:%M\")\n",
    "    \n",
    "    output = \"{h}: {num} average comments per posts\".format(h = dt_hour, num = avg)\n",
    "    \n",
    "    print(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacker New Ask Posts Analysis Conclusion\n",
    "\n",
    "As you can see 3:00pm, 1:00pm, 5:00pm, 8:00pm, and 10:00 am are in the top 5 hours (in that order) for posting if you would like to receive a high number of comments on your post. \n",
    "\n",
    "We should note though, that posting at 3:00pm results in about 3 times as many comments then posting at any of other top 5 hours. \n",
    "\n",
    "So, if your goal is to post a popular submission which will receive a high number of visitors and comments, posting an Ask HN submission at 3:00pm is your best bet!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
